{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p4BYc1dOdKne"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "file_path = '/content/CancerFactorsData.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your input features and target variable\n",
        "features = ['Smoking', 'Obesity', 'Poverty', 'Uninsured', 'PM2.5']\n",
        "target = 'LungCancerRates'\n",
        "\n",
        "# Ensure data is sorted by time\n",
        "df = df.sort_index()\n",
        "\n",
        "# Normalize the features and the target separately\n",
        "scaler_features = MinMaxScaler()\n",
        "scaler_target = MinMaxScaler()\n",
        "\n",
        "df[features] = scaler_features.fit_transform(df[features])\n",
        "df[[target]] = scaler_target.fit_transform(df[[target]])\n",
        "\n",
        "# Creating input sequences for LSTM\n",
        "def create_sequences(df, features, target, sequence_length=10):\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        X.append(df[features].iloc[i:i+sequence_length].values)\n",
        "        y.append(df[target].iloc[i+sequence_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "sequence_length = 10\n",
        "X, y = create_sequences(df, features, target, sequence_length)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Creating Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM layers with Dropout for regularization\n",
        "model.add(LSTM(64, input_shape=(sequence_length, len(features)), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Adding Dense layer for regression output\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Evaluating the model\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Making predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverse transform the target values\n",
        "y_test_original = scaler_target.inverse_transform(y_test.reshape(-1, 1))\n",
        "predictions_original = scaler_target.inverse_transform(predictions)\n",
        "\n",
        "# Calculating and printing metrics\n",
        "mae = mean_absolute_error(y_test_original, predictions_original)\n",
        "mse = mean_squared_error(y_test_original, predictions_original)\n",
        "r2 = r2_score(y_test_original, predictions_original)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"R-squared (R²): {r2}\")\n",
        "\n",
        "# Printing sample predicted and actual values for comparison\n",
        "print(\"Sample predictions and actual values:\")\n",
        "for i in range(5):  # Print first 5 samples for comparison\n",
        "    print(f\"Predicted: {predictions_original[i][0]}, Actual: {y_test_original[i][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaoY7Z0ndQ07",
        "outputId": "473c6954-7013-4ecb-b0f5-7cbc27058299"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 5s 468ms/step - loss: 0.2418 - mae: 0.4468 - val_loss: 0.1844 - val_mae: 0.3338\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1088 - mae: 0.2725 - val_loss: 0.1045 - val_mae: 0.2471\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0526 - mae: 0.1891 - val_loss: 0.1001 - val_mae: 0.2680\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0650 - mae: 0.2117 - val_loss: 0.1082 - val_mae: 0.2826\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0661 - mae: 0.2040 - val_loss: 0.0969 - val_mae: 0.2649\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0530 - mae: 0.1856 - val_loss: 0.0910 - val_mae: 0.2521\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0530 - mae: 0.1834 - val_loss: 0.0921 - val_mae: 0.2435\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0482 - mae: 0.1784 - val_loss: 0.0931 - val_mae: 0.2404\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0456 - mae: 0.1739 - val_loss: 0.0930 - val_mae: 0.2396\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1706 - val_loss: 0.0906 - val_mae: 0.2426\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0452 - mae: 0.1704 - val_loss: 0.0892 - val_mae: 0.2455\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0461 - mae: 0.1733 - val_loss: 0.0885 - val_mae: 0.2482\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0456 - mae: 0.1717 - val_loss: 0.0882 - val_mae: 0.2484\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0477 - mae: 0.1818 - val_loss: 0.0880 - val_mae: 0.2481\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0423 - mae: 0.1703 - val_loss: 0.0880 - val_mae: 0.2473\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0553 - mae: 0.1830 - val_loss: 0.0884 - val_mae: 0.2446\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0530 - mae: 0.1825 - val_loss: 0.0895 - val_mae: 0.2415\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0487 - mae: 0.1768 - val_loss: 0.0898 - val_mae: 0.2407\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0446 - mae: 0.1706 - val_loss: 0.0897 - val_mae: 0.2407\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0464 - mae: 0.1718 - val_loss: 0.0890 - val_mae: 0.2420\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0492 - mae: 0.1755 - val_loss: 0.0883 - val_mae: 0.2437\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0470 - mae: 0.1755 - val_loss: 0.0879 - val_mae: 0.2448\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0439 - mae: 0.1653 - val_loss: 0.0876 - val_mae: 0.2460\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0466 - mae: 0.1750 - val_loss: 0.0874 - val_mae: 0.2457\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.0450 - mae: 0.1717 - val_loss: 0.0871 - val_mae: 0.2458\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0478 - mae: 0.1768 - val_loss: 0.0872 - val_mae: 0.2441\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0417 - mae: 0.1652 - val_loss: 0.0875 - val_mae: 0.2425\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0497 - mae: 0.1751 - val_loss: 0.0874 - val_mae: 0.2422\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.0437 - mae: 0.1684 - val_loss: 0.0872 - val_mae: 0.2421\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 98ms/step - loss: 0.0432 - mae: 0.1692 - val_loss: 0.0866 - val_mae: 0.2432\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0417 - mae: 0.1651 - val_loss: 0.0861 - val_mae: 0.2446\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0441 - mae: 0.1643 - val_loss: 0.0861 - val_mae: 0.2441\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0437 - mae: 0.1656 - val_loss: 0.0866 - val_mae: 0.2417\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0465 - mae: 0.1748 - val_loss: 0.0875 - val_mae: 0.2395\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 162ms/step - loss: 0.0434 - mae: 0.1690 - val_loss: 0.0868 - val_mae: 0.2410\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0448 - mae: 0.1707 - val_loss: 0.0859 - val_mae: 0.2441\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0517 - mae: 0.1784 - val_loss: 0.0858 - val_mae: 0.2441\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0458 - mae: 0.1674 - val_loss: 0.0859 - val_mae: 0.2428\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0453 - mae: 0.1723 - val_loss: 0.0865 - val_mae: 0.2405\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0480 - mae: 0.1758 - val_loss: 0.0875 - val_mae: 0.2382\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0491 - mae: 0.1782 - val_loss: 0.0867 - val_mae: 0.2397\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0443 - mae: 0.1664 - val_loss: 0.0856 - val_mae: 0.2424\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0490 - mae: 0.1782 - val_loss: 0.0855 - val_mae: 0.2428\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0443 - mae: 0.1658 - val_loss: 0.0853 - val_mae: 0.2427\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0432 - mae: 0.1685 - val_loss: 0.0850 - val_mae: 0.2435\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0480 - mae: 0.1718 - val_loss: 0.0851 - val_mae: 0.2427\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0434 - mae: 0.1749 - val_loss: 0.0856 - val_mae: 0.2407\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0459 - mae: 0.1688 - val_loss: 0.0860 - val_mae: 0.2396\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0462 - mae: 0.1715 - val_loss: 0.0855 - val_mae: 0.2405\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0465 - mae: 0.1678 - val_loss: 0.0851 - val_mae: 0.2415\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0444 - mae: 0.1644 - val_loss: 0.0849 - val_mae: 0.2426\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0477 - mae: 0.1760 - val_loss: 0.0849 - val_mae: 0.2428\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0453 - mae: 0.1750 - val_loss: 0.0849 - val_mae: 0.2423\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0450 - mae: 0.1674 - val_loss: 0.0846 - val_mae: 0.2438\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0476 - mae: 0.1767 - val_loss: 0.0847 - val_mae: 0.2416\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0446 - mae: 0.1648 - val_loss: 0.0885 - val_mae: 0.2372\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0430 - mae: 0.1622 - val_loss: 0.0896 - val_mae: 0.2368\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0462 - mae: 0.1700 - val_loss: 0.0872 - val_mae: 0.2380\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0439 - mae: 0.1660 - val_loss: 0.0853 - val_mae: 0.2393\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0423 - mae: 0.1654 - val_loss: 0.0846 - val_mae: 0.2406\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.0443 - mae: 0.1640 - val_loss: 0.0844 - val_mae: 0.2407\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0437 - mae: 0.1678 - val_loss: 0.0842 - val_mae: 0.2397\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0433 - mae: 0.1600 - val_loss: 0.0840 - val_mae: 0.2390\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0441 - mae: 0.1681 - val_loss: 0.0851 - val_mae: 0.2375\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.0401 - mae: 0.1586 - val_loss: 0.0838 - val_mae: 0.2387\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0448 - mae: 0.1680 - val_loss: 0.0830 - val_mae: 0.2417\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0447 - mae: 0.1684 - val_loss: 0.0838 - val_mae: 0.2388\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0405 - mae: 0.1622 - val_loss: 0.0839 - val_mae: 0.2390\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0438 - mae: 0.1675 - val_loss: 0.0833 - val_mae: 0.2394\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0448 - mae: 0.1668 - val_loss: 0.0834 - val_mae: 0.2398\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0439 - mae: 0.1626 - val_loss: 0.0839 - val_mae: 0.2395\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0421 - mae: 0.1605 - val_loss: 0.0836 - val_mae: 0.2404\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0419 - mae: 0.1594 - val_loss: 0.0842 - val_mae: 0.2401\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0421 - mae: 0.1614 - val_loss: 0.0848 - val_mae: 0.2399\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0443 - mae: 0.1661 - val_loss: 0.0854 - val_mae: 0.2396\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0427 - mae: 0.1642 - val_loss: 0.0841 - val_mae: 0.2414\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0449 - mae: 0.1651 - val_loss: 0.0839 - val_mae: 0.2428\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0481 - mae: 0.1754 - val_loss: 0.0848 - val_mae: 0.2408\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0428 - mae: 0.1637 - val_loss: 0.0880 - val_mae: 0.2384\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0447 - mae: 0.1666 - val_loss: 0.0861 - val_mae: 0.2392\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0441 - mae: 0.1667 - val_loss: 0.0841 - val_mae: 0.2408\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0455 - mae: 0.1727 - val_loss: 0.0834 - val_mae: 0.2433\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0453 - mae: 0.1676 - val_loss: 0.0833 - val_mae: 0.2420\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0435 - mae: 0.1650 - val_loss: 0.0867 - val_mae: 0.2378\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0462 - mae: 0.1736 - val_loss: 0.0924 - val_mae: 0.2382\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0472 - mae: 0.1729 - val_loss: 0.0882 - val_mae: 0.2369\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0426 - mae: 0.1648 - val_loss: 0.0829 - val_mae: 0.2406\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.0422 - mae: 0.1620 - val_loss: 0.0825 - val_mae: 0.2416\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0373 - mae: 0.1554 - val_loss: 0.0829 - val_mae: 0.2394\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0448 - mae: 0.1681 - val_loss: 0.0834 - val_mae: 0.2379\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0376 - mae: 0.1506 - val_loss: 0.0822 - val_mae: 0.2381\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0416 - mae: 0.1622 - val_loss: 0.0817 - val_mae: 0.2380\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0441 - mae: 0.1588 - val_loss: 0.0826 - val_mae: 0.2367\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.0428 - mae: 0.1565 - val_loss: 0.0845 - val_mae: 0.2356\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0430 - mae: 0.1605 - val_loss: 0.0875 - val_mae: 0.2346\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0454 - mae: 0.1644 - val_loss: 0.0848 - val_mae: 0.2366\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0422 - mae: 0.1633 - val_loss: 0.0832 - val_mae: 0.2388\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0426 - mae: 0.1610 - val_loss: 0.0824 - val_mae: 0.2411\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0464 - mae: 0.1712 - val_loss: 0.0840 - val_mae: 0.2398\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0457 - mae: 0.1721 - val_loss: 0.0883 - val_mae: 0.2377\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0883 - mae: 0.2377\n",
            "1/1 [==============================] - 1s 741ms/step\n",
            "Mean Absolute Error (MAE): 0.158145133750098\n",
            "Mean Squared Error (MSE): 0.03911101811385579\n",
            "R-squared (R²): -0.05255449646290433\n",
            "Sample predictions and actual values:\n",
            "Predicted: 0.7891573309898376, Actual: 0.506981085\n",
            "Predicted: 0.7416291832923889, Actual: 1.172392701\n",
            "Predicted: 0.7238859534263611, Actual: 0.599855419\n",
            "Predicted: 0.715394139289856, Actual: 0.898569936\n",
            "Predicted: 0.7325436472892761, Actual: 0.587655046\n"
          ]
        }
      ]
    }
  ]
}